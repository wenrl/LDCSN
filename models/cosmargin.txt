class CosMarginProduct_1(nn.Module):
    r"""Implement of large margin cosine distance: :
    Args:
        in_features: size of each input sample
        out_features: size of each output sample
        s: norm of input feature
        m: margin
    """

    def __init__(self, in_features, out_features, s=30.0, m=0.35,std=0.05):
        super(CosMarginProduct_1, self).__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.s = s
        self.m = m
        self.std = std
        self.weight = Parameter(torch.Tensor(out_features, in_features))
        nn.init.xavier_uniform_(self.weight)
        #stdv = 1. / math.sqrt(self.weight.size(1))
        #self.weight.data.uniform_(-stdv, stdv)

    def forward(self, input, label):
        cosine = F.linear(F.normalize(input), F.normalize(self.weight))
        index = torch.where(label != -1)[0]
        m_hot = torch.zeros(index.size()[0], cosine.size()[1], device=cosine.device)
        margin = torch.normal(mean=self.m, std=self.std, size=label[index, None].size(),
                              device=cosine.device)  # Fast converge .clamp(self.m-self.std, self.m+self.std)
        m_hot.scatter_(1, label[index, None], margin)
        phi = cosine - m_hot
        # --------------------------- convert label to one-hot ---------------------------
        # one_hot = torch.zeros(cosine.size(), device='cuda')
        one_hot = torch.zeros(cosine.size(), device='cuda')
        # one_hot = one_hot.cuda() if cosine.is_cuda else one_hot
        # print(one_hot.shape, label.shape)
        one_hot.scatter_(1, label.view(-1, 1).long(), 1)

        # one_hot.scatter_(1, label.view(-1, 1).long(), 1)
        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------
        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)
        # you can use torch.where if your torch.__version__ is 0.4
        output *= self.s
        # print(output[0])
        # output+=b
        # cosine = cosine_sim(input, self.weight)
        # # cosine = F.linear(F.normalize(input), F.normalize(self.weight))
        # # --------------------------- convert label to one-hot ---------------------------
        # # https://discuss.pytorch.org/t/convert-int-into-one-hot-format/507
        # one_hot = torch.zeros_like(cosine)
        # index = torch.where(label!=-1)[0]
        # margin = torch.normal(mean=self.m, std=self.std, size=label[index, None].size(), device=cosine.device)
        # one_hot.scatter_(1, label.view(-1, 1), margin)
        # # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------
        # output = self.s * (cosine - one_hot)

        return output

    def __repr__(self):
        return self.__class__.__name__ + '(' \
               + 'in_features=' + str(self.in_features) \
               + ', out_features=' + str(self.out_features) \
               + ', s=' + str(self.s) \
               + ', m=' + str(self.m) + ')'